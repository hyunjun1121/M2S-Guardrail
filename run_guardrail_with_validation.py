#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import pandas as pd
import torch
from transformers import (
    AutoTokenizer, AutoModelForSequenceClassification, 
    AutoModelForCausalLM, TrainingArguments, Trainer,
    DataCollatorForLanguageModeling, DataCollatorWithPadding
)
from datasets import Dataset
import argparse
import json

def format_llama_guard_data(turns_list):
    """Llama-Guard í˜•ì‹ìœ¼ë¡œ ëŒ€í™” ë°ì´í„° í¬ë§·íŒ…"""
    conversations = []
    
    # ê° í„´ì„ ê°œë³„ ëŒ€í™”ë¡œ ì²˜ë¦¬
    for i, turn in enumerate(turns_list):
        if turn and str(turn).strip():
            # Llama-Guard í‘œì¤€ í˜•ì‹
            formatted_conversation = f"""<s>[INST] {str(turn).strip()} [/INST] unsafe

Category: O1
Category explanation: The message contains potentially harmful content that could lead to dangerous or illegal activities.</s>"""
            conversations.append(formatted_conversation)
    
    # ëˆ„ì  ì»¨í…ìŠ¤íŠ¸ ë²„ì „ë„ ì¶”ê°€ (multi-turn í•™ìŠµìš©)
    if len(turns_list) > 1:
        cumulative_context = ""
        for i, turn in enumerate(turns_list):
            if turn and str(turn).strip():
                if cumulative_context:
                    cumulative_context += f"\n\nUser: {str(turn).strip()}"
                else:
                    cumulative_context = f"User: {str(turn).strip()}"
                
                # ëˆ„ì ëœ ì»¨í…ìŠ¤íŠ¸ë¡œ ì•ˆì „ì„± íŒë‹¨
                formatted_cumulative = f"""<s>[INST] {cumulative_context} [/INST] unsafe

Category: O1  
Category explanation: This multi-turn conversation contains escalating harmful content designed to bypass safety measures.</s>"""
                conversations.append(formatted_cumulative)
    
    return conversations

def format_prompt_guard_data(turns_list):
    """Prompt-Guard í˜•ì‹ìœ¼ë¡œ ë°ì´í„° í¬ë§·íŒ… (injection íƒì§€ìš©)"""
    prompts_and_labels = []
    
    # ê° í„´ì„ prompt injectionìœ¼ë¡œ ë¶„ë¥˜
    for turn in turns_list:
        if turn and str(turn).strip():
            prompts_and_labels.append({
                'text': str(turn).strip(),
                'label': 1  # 1 = injection/jailbreak
            })
    
    return prompts_and_labels

def process_harmful_dataset(data_file, model_type):
    """Harmful ë°ì´í„°ì…‹ì„ Guardrail í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    print(f"ë°ì´í„° ë¡œë“œ ì¤‘: {data_file}")
    df = pd.read_excel(data_file)
    
    all_training_data = []
    
    for idx, row in df.iterrows():
        if idx % 1000 == 0:
            print(f"Processing {idx}/{len(df)} rows...")
        
        turns = []
        
        # M2S ì••ì¶•ëœ ë°ì´í„°ì¸ ê²½ìš°
        if 'prompt' in row and pd.notna(row['prompt']):
            # M2S ì „ì²´ í”„ë¡¬í”„íŠ¸ë¥¼ harmfulë¡œ ì²˜ë¦¬
            if model_type == "llama_guard":
                formatted = f"""<s>[INST] {str(row['prompt'])} [/INST] unsafe

Category: O1
Category explanation: This is a multi-turn jailbreak attempt using structured prompting to bypass safety measures.</s>"""
                all_training_data.append(formatted)
            else:  # prompt_guard
                all_training_data.append({
                    'text': str(row['prompt']),
                    'label': 1
                })
        
        # ì›ë³¸ í„´ ë°ì´í„°ì¸ ê²½ìš°
        else:
            # turn_1ë¶€í„° turn_12ê¹Œì§€ ì¶”ì¶œ
            for i in range(1, 13):
                turn_col = f'turn_{i}'
                if turn_col in row and pd.notna(row[turn_col]):
                    turns.append(str(row[turn_col]).strip())
            
            if turns:
                if model_type == "llama_guard":
                    formatted_conversations = format_llama_guard_data(turns)
                    all_training_data.extend(formatted_conversations)
                else:  # prompt_guard
                    formatted_prompts = format_prompt_guard_data(turns)
                    all_training_data.extend(formatted_prompts)
    
    print(f"ì´ í›ˆë ¨ ìƒ˜í”Œ ìˆ˜: {len(all_training_data)}")
    return all_training_data

def create_llama_guard_dataset(training_data, tokenizer, max_length=1024):
    """Llama-Guardìš© ë°ì´í„°ì…‹ ìƒì„±"""
    def tokenize_function(examples):
        # ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ í† í°í™” (input + output í¬í•¨)
        tokenized = tokenizer(
            examples['text'],
            truncation=True,
            padding=False,
            max_length=max_length,
            return_tensors=None
        )
        # ì–¸ì–´ ëª¨ë¸ë§: ì…ë ¥ê³¼ ì¶œë ¥ì´ ë™ì¼
        tokenized['labels'] = tokenized['input_ids'].copy()
        return tokenized
    
    dataset = Dataset.from_dict({"text": training_data})
    tokenized_dataset = dataset.map(tokenize_function, batched=True)
    return tokenized_dataset

def create_prompt_guard_dataset(training_data, tokenizer, max_length=512):
    """Prompt-Guardìš© ë°ì´í„°ì…‹ ìƒì„±"""
    texts = [item['text'] for item in training_data]
    labels = [item['label'] for item in training_data]
    
    def tokenize_function(examples):
        return tokenizer(
            examples['text'],
            truncation=True,
            padding=False,
            max_length=max_length,
            return_tensors=None
        )
    
    dataset = Dataset.from_dict({"text": texts, "labels": labels})
    tokenized_dataset = dataset.map(tokenize_function, batched=True)
    return tokenized_dataset

def run_guardrail_with_validation(model_name, train_file, val_file, experiment_name):
    """Train/Validationìœ¼ë¡œ ë¶„í• ëœ ë°ì´í„°ë¡œ Guardrail Fine-tuning"""
    
    print(f"ğŸš€ Guardrail Fine-tuning ì‹œì‘ (with Validation)")
    print(f"ëª¨ë¸: {model_name}")
    print(f"Train ë°ì´í„°: {train_file}")
    print(f"Validation ë°ì´í„°: {val_file}")
    print(f"ì‹¤í—˜: {experiment_name}")
    
    # ëª¨ë¸ ê²½ë¡œ ì„¤ì •
    model_paths = {
        "Llama-Guard-4-12B": "./models/Llama-Guard-4-12B",
        "Llama-Prompt-Guard-2-86M": "./models/Llama-Prompt-Guard-2-86M"
    }
    
    model_path = model_paths[model_name]
    
    # ëª¨ë¸ íƒ€ì… ê²°ì •
    if "Prompt-Guard" in model_name:
        model_type = "prompt_guard"
        max_length = 512
    else:
        model_type = "llama_guard"  
        max_length = 1024
    
    print(f"ëª¨ë¸ íƒ€ì…: {model_type}")
    
    # í† í¬ë‚˜ì´ì € ë¡œë“œ
    print("í† í¬ë‚˜ì´ì € ë¡œë“œ ì¤‘...")
    tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)
    if tokenizer.pad_token is None:
        tokenizer.pad_token = tokenizer.eos_token
    
    # ëª¨ë¸ ë¡œë“œ
    print("ëª¨ë¸ ë¡œë“œ ì¤‘...")
    if model_type == "prompt_guard":
        model = AutoModelForSequenceClassification.from_pretrained(
            model_path,
            torch_dtype=torch.bfloat16,
            device_map="auto",
            trust_remote_code=True
        )
    else:  # llama_guard
        model = AutoModelForCausalLM.from_pretrained(
            model_path,
            torch_dtype=torch.bfloat16,
            device_map="auto",
            trust_remote_code=True,
            use_cache=False
        )
    
    print(f"ëª¨ë¸ íŒŒë¼ë¯¸í„°: {model.num_parameters():,}")
    
    # Train ë°ì´í„° ì²˜ë¦¬
    print("Train ë°ì´í„°ì…‹ ì²˜ë¦¬ ì¤‘...")
    train_data = process_harmful_dataset(train_file, model_type)
    
    # Validation ë°ì´í„° ì²˜ë¦¬
    val_data = None
    if val_file and os.path.exists(val_file):
        print("Validation ë°ì´í„°ì…‹ ì²˜ë¦¬ ì¤‘...")
        val_data = process_harmful_dataset(val_file, model_type)
    
    # ìƒ˜í”Œë§ (ë©”ëª¨ë¦¬ ì ˆì•½)
    train_sample_size = min(5000, len(train_data))
    if len(train_data) > train_sample_size:
        import random
        train_data = random.sample(train_data, train_sample_size)
        print(f"Train ìƒ˜í”Œë§: {train_sample_size}ê°œ ì‚¬ìš©")
    
    if val_data:
        val_sample_size = min(1000, len(val_data))
        if len(val_data) > val_sample_size:
            import random
            val_data = random.sample(val_data, val_sample_size)
            print(f"Validation ìƒ˜í”Œë§: {val_sample_size}ê°œ ì‚¬ìš©")
    
    # ë°ì´í„°ì…‹ ìƒì„±
    if model_type == "prompt_guard":
        train_dataset = create_prompt_guard_dataset(train_data, tokenizer, max_length)
        val_dataset = create_prompt_guard_dataset(val_data, tokenizer, max_length) if val_data else None
        data_collator = DataCollatorWithPadding(tokenizer=tokenizer)
    else:
        train_dataset = create_llama_guard_dataset(train_data, tokenizer, max_length)
        val_dataset = create_llama_guard_dataset(val_data, tokenizer, max_length) if val_data else None
        data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)
    
    # ì¶œë ¥ ë””ë ‰í„°ë¦¬
    output_dir = f"./fine_tuned_models/{model_name.replace('/', '_')}_{experiment_name}"
    os.makedirs(output_dir, exist_ok=True)
    
    # í›ˆë ¨ ì„¤ì •
    if "86M" in model_name:  # ì‘ì€ ëª¨ë¸
        training_args = TrainingArguments(
            output_dir=output_dir,
            overwrite_output_dir=True,
            num_train_epochs=3,
            per_device_train_batch_size=4,
            per_device_eval_batch_size=4,
            gradient_accumulation_steps=4,
            learning_rate=2e-5,
            weight_decay=0.01,
            logging_steps=50,
            save_steps=500,
            eval_steps=500,
            save_strategy="steps",
            eval_strategy="steps" if val_dataset else "no",
            load_best_model_at_end=True if val_dataset else False,
            metric_for_best_model="eval_loss" if val_dataset else None,
            fp16=True,
            gradient_checkpointing=True,
            dataloader_pin_memory=False,
            remove_unused_columns=False,
            report_to=None,
        )
    else:  # í° ëª¨ë¸ (12B)
        training_args = TrainingArguments(
            output_dir=output_dir,
            overwrite_output_dir=True,
            num_train_epochs=2,
            per_device_train_batch_size=1,
            per_device_eval_batch_size=1,
            gradient_accumulation_steps=8,
            learning_rate=1e-5,
            weight_decay=0.01,
            logging_steps=25,
            save_steps=250,
            eval_steps=250,
            save_strategy="steps",
            eval_strategy="steps" if val_dataset else "no",
            load_best_model_at_end=True if val_dataset else False,
            metric_for_best_model="eval_loss" if val_dataset else None,
            fp16=True,
            gradient_checkpointing=True,
            dataloader_pin_memory=False,
            remove_unused_columns=False,
            report_to=None,
        )
    
    # Trainer ì„¤ì •
    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        eval_dataset=val_dataset,
        data_collator=data_collator,
        tokenizer=tokenizer,
    )
    
    # í›ˆë ¨ ì‹¤í–‰
    print("ğŸ”¥ Fine-tuning ì‹œì‘...")
    trainer.train()
    
    # ëª¨ë¸ ì €ì¥
    print("ğŸ’¾ ëª¨ë¸ ì €ì¥ ì¤‘...")
    trainer.save_model()
    tokenizer.save_pretrained(output_dir)
    
    # í›ˆë ¨ í†µê³„ ì €ì¥
    stats = {
        "model_name": model_name,
        "model_type": model_type,
        "experiment_name": experiment_name,
        "train_file": train_file,
        "val_file": val_file,
        "train_samples": len(train_data),
        "val_samples": len(val_data) if val_data else 0,
        "output_dir": output_dir,
        "max_length": max_length,
        "model_parameters": model.num_parameters()
    }
    
    with open(os.path.join(output_dir, "training_stats.json"), 'w') as f:
        json.dump(stats, f, indent=2)
    
    print(f"âœ… Fine-tuning ì™„ë£Œ!")
    print(f"ğŸ“ ëª¨ë¸ ì €ì¥ ìœ„ì¹˜: {output_dir}")
    print(f"ğŸ“Š Train ìƒ˜í”Œ: {len(train_data)}")
    print(f"ğŸ“Š Validation ìƒ˜í”Œ: {len(val_data) if val_data else 0}")
    
    # ë©”ëª¨ë¦¬ ì •ë¦¬
    del trainer, model
    torch.cuda.empty_cache()
    
    return output_dir

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Guardrail Model Fine-tuning with Train/Validation Split')
    parser.add_argument('--model', required=True, 
                       choices=['Llama-Guard-4-12B', 'Llama-Prompt-Guard-2-86M'],
                       help='Guardrail model to fine-tune')
    parser.add_argument('--train', required=True, 
                       help='Path to training dataset (Excel file)')
    parser.add_argument('--val', required=False,
                       help='Path to validation dataset (Excel file)')
    parser.add_argument('--name', required=True,
                       help='Experiment name')
    
    args = parser.parse_args()
    
    try:
        result_dir = run_guardrail_with_validation(args.model, args.train, args.val, args.name)
        print(f"\nğŸ‰ ì‹¤í—˜ ì„±ê³µ! ê²°ê³¼: {result_dir}")
    except Exception as e:
        print(f"\nâŒ ì‹¤í—˜ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()