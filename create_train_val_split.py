#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
import os

def split_dataset_by_source(data_file, test_size=0.2, random_state=42):
    """ê° sourceë³„ë¡œ ë¹„ìœ¨ì„ ë§ì¶°ì„œ train/validation ë¶„í• """
    
    print(f"ë°ì´í„° ë¡œë“œ: {data_file}")
    df = pd.read_excel(data_file)
    
    print(f"ì „ì²´ ë°ì´í„°: {len(df)} rows")
    
    # Sourceë³„ ë¶„í¬ í™•ì¸
    print("\n=== Sourceë³„ ë¶„í¬ ===")
    source_counts = df['source'].value_counts()
    for source, count in source_counts.items():
        print(f"{source}: {count} ({count/len(df)*100:.1f}%)")
    
    # ê° sourceë³„ë¡œ train/val ë¶„í• 
    train_dfs = []
    val_dfs = []
    
    for source in source_counts.index:
        source_df = df[df['source'] == source]
        
        if len(source_df) >= 2:  # ìµœì†Œ 2ê°œ ì´ìƒì¸ ê²½ìš°ë§Œ ë¶„í• 
            train_source, val_source = train_test_split(
                source_df, 
                test_size=test_size, 
                random_state=random_state,
                shuffle=True
            )
            train_dfs.append(train_source)
            val_dfs.append(val_source)
            print(f"{source}: train={len(train_source)}, val={len(val_source)}")
        else:
            # ë°ì´í„°ê°€ 1ê°œë¿ì´ë©´ trainì—ë§Œ í¬í•¨
            train_dfs.append(source_df)
            print(f"{source}: train={len(source_df)}, val=0 (too few samples)")
    
    # ë°ì´í„°í”„ë ˆì„ ê²°í•©
    train_df = pd.concat(train_dfs, ignore_index=True)
    val_df = pd.concat(val_dfs, ignore_index=True) if val_dfs else pd.DataFrame()
    
    # ì…”í”Œ
    train_df = train_df.sample(frac=1, random_state=random_state).reset_index(drop=True)
    if len(val_df) > 0:
        val_df = val_df.sample(frac=1, random_state=random_state).reset_index(drop=True)
    
    print(f"\n=== ë¶„í•  ê²°ê³¼ ===")
    print(f"Train: {len(train_df)} rows ({len(train_df)/len(df)*100:.1f}%)")
    print(f"Validation: {len(val_df)} rows ({len(val_df)/len(df)*100:.1f}%)")
    
    # íŒŒì¼ëª… ìƒì„±
    base_name = data_file.replace('.xlsx', '')
    train_file = f"{base_name}_train.xlsx"
    val_file = f"{base_name}_val.xlsx"
    
    # ì €ì¥
    train_df.to_excel(train_file, index=False)
    print(f"Train ë°ì´í„° ì €ì¥: {train_file}")
    
    if len(val_df) > 0:
        val_df.to_excel(val_file, index=False)
        print(f"Validation ë°ì´í„° ì €ì¥: {val_file}")
    
    # Validationì—ì„œë„ source ë¶„í¬ í™•ì¸
    if len(val_df) > 0:
        print(f"\n=== Validation Source ë¶„í¬ ===")
        val_source_counts = val_df['source'].value_counts()
        for source, count in val_source_counts.items():
            print(f"{source}: {count} ({count/len(val_df)*100:.1f}%)")
    
    return train_file, val_file

def main():
    """ëª¨ë“  ë°ì´í„°ì…‹ì— ëŒ€í•´ train/val ë¶„í•  ìˆ˜í–‰"""
    
    datasets = [
        "integrated_data.xlsx",
        "m2s_hyphenize_data.xlsx", 
        "m2s_numberize_data.xlsx",
        "m2s_pythonize_data.xlsx",
        "m2s_combined_all_data.xlsx"
    ]
    
    results = {}
    
    for dataset in datasets:
        if os.path.exists(dataset):
            print(f"\n{'='*60}")
            print(f"ì²˜ë¦¬ ì¤‘: {dataset}")
            print(f"{'='*60}")
            
            try:
                train_file, val_file = split_dataset_by_source(dataset)
                results[dataset] = {
                    'train': train_file,
                    'validation': val_file
                }
            except Exception as e:
                print(f"âŒ {dataset} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        else:
            print(f"âš ï¸  íŒŒì¼ ì—†ìŒ: {dataset}")
    
    # ê²°ê³¼ ìš”ì•½
    print(f"\n{'='*60}")
    print("ğŸ“‹ ë¶„í•  ì™„ë£Œ ìš”ì•½")
    print(f"{'='*60}")
    
    for dataset, files in results.items():
        print(f"\nğŸ“ {dataset}")
        print(f"  â”œâ”€â”€ Train: {files['train']}")
        print(f"  â””â”€â”€ Validation: {files['validation']}")

if __name__ == "__main__":
    main()